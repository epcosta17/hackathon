# B2B AI Talent Analysis App

An intelligent application for analyzing talent through interview transcripts. Upload audio interviews, get AI-powered transcriptions with timestamps, and receive comprehensive analysis of candidate skills, communication abilities, and technical competencies.

## âœ¨ Features

- ğŸ¤ **Audio Upload** - Support for MP3 and WAV files up to 100MB
- ğŸ“ **Smart Transcription** - Automatic speech-to-text with word-level timestamps using whisper.cpp
- âœï¸ **Interactive Editor** - Edit transcripts with precision, add notes and bookmarks
- ğŸ¤– **AI Analysis** - Comprehensive talent assessment powered by Google Gemini:
  - Technical skills evaluation
  - Communication and attitude analysis
  - Coding challenge insights
  - Key technical emphasis points
  - Interview statistics and metrics
- ğŸ“Š **Beautiful Dashboards** - Modern UI with detailed visualizations
- ğŸ’¾ **Interview Management** - Save, search, and revisit past interviews
- ğŸ“„ **Report Generation** - Download detailed analysis reports as DOCX files

## ğŸš€ Quick Start

### Prerequisites

1. **Homebrew** (macOS package manager)
   ```bash
   /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
   ```

2. **Python 3.12+**
   ```bash
   brew install python3
   python3 --version
   ```

3. **Node.js 18+**
   ```bash
   brew install node
   node --version
   ```

4. **whisper.cpp** (for local transcription)
   ```bash
   brew install whisper-cpp
   ```

### Installation

#### 1. Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Download Whisper model (only needed once)
cd ai
./download-ggml-model.sh
cd ..

# Optional: Add Google Gemini API key for AI analysis
# Create a .env file in the backend directory:
echo "GEMINI_API_KEY=your_api_key_here" > .env

# Start the backend server
python main.py
```

The backend will be available at `http://127.0.0.1:8000`

Interactive API docs: `http://127.0.0.1:8000/`

#### 2. Frontend Setup

Open a new terminal window:

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install

# Start the development server
npm run dev
```

The frontend will be available at `http://localhost:5173`

## ğŸ—ï¸ Project Structure

```
hackathon/
â”œâ”€â”€ backend/                      # Python FastAPI backend
â”‚   â”œâ”€â”€ main.py                  # Application entry point
â”‚   â”œâ”€â”€ database.py              # SQLite database operations
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic data models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ transcription_service.py  # Audio transcription
â”‚   â”‚   â”œâ”€â”€ analysis_service.py       # AI analysis
â”‚   â”‚   â””â”€â”€ docx_service.py          # Report generation
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ transcription.py    # Transcription endpoints
â”‚   â”‚   â”œâ”€â”€ analysis.py         # Analysis endpoints
â”‚   â”‚   â”œâ”€â”€ interviews.py       # Interview CRUD
â”‚   â”‚   â””â”€â”€ notes.py            # Notes & bookmarks
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ ggml-base.bin      # Whisper model
â”‚   â”‚   â””â”€â”€ PROMPT_JSON.md     # AI prompts
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ frontend/                    # React TypeScript frontend
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ UploadScreen.tsx
    â”‚   â”‚   â”œâ”€â”€ TranscriptEditor.tsx
    â”‚   â”‚   â””â”€â”€ AnalysisDashboard.tsx
    â”‚   â””â”€â”€ App.tsx
    â”œâ”€â”€ package.json
    â””â”€â”€ vite.config.ts
```

## ğŸ”§ Technology Stack

### Backend
- **FastAPI** - Modern Python web framework
- **whisper.cpp** - Fast, local speech recognition (Metal-accelerated on Apple Silicon)
- **Google Gemini** - AI-powered interview analysis
- **SQLite** - Local database for interviews and notes
- **python-docx** - Report generation
- **Pydantic** - Data validation

### Frontend
- **React 18** - UI framework
- **TypeScript** - Type safety
- **Vite** - Lightning-fast build tool
- **Tailwind CSS** - Utility-first styling
- **shadcn/ui** - Beautiful component library
- **Framer Motion** - Smooth animations

## ğŸ¯ Usage

1. **Start both servers** (backend and frontend in separate terminals)
2. **Open your browser** to `http://localhost:5173`
3. **Upload an audio file** (MP3 or WAV) of an interview
4. **Review the transcript** - Edit, add notes, or bookmark important moments
5. **Run AI analysis** - Get comprehensive insights
6. **Save the interview** - Access it anytime from "Previous Interviews"
7. **Download report** - Export analysis as a Word document

## ğŸ“– API Documentation

Once the backend is running, visit:
- **Interactive API docs**: `http://127.0.0.1:8000/`
- **Alternative docs**: `http://127.0.0.1:8000/redoc`

### Key Endpoints

- `GET /api/ping` - Health check
- `POST /api/transcribe-stream` - Upload audio for transcription (SSE stream)
- `POST /api/analyze` - Analyze transcript with AI
- `POST /api/interviews` - Save interview with notes
- `GET /api/interviews` - List and search interviews
- `POST /api/download-report` - Download DOCX report

## ğŸ› Troubleshooting

### Backend Issues

**Port 8000 already in use:**
```bash
lsof -ti:8000 | xargs kill -9
```

**whisper.cpp not found:**
```bash
brew install whisper-cpp
```

**Model not found:**
```bash
cd backend/ai
./download-ggml-model.sh
```

**Python dependencies issues:**
```bash
cd backend
rm -rf .venv
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### Frontend Issues

**Port 5173 already in use:**
- Vite will automatically use the next available port
- Check terminal output for the actual URL

**Module not found errors:**
```bash
cd frontend
rm -rf node_modules package-lock.json
npm install
```

**Cannot connect to backend:**
- Ensure backend is running on port 8000
- Check browser console for errors
- Verify both servers are running

## ğŸš¢ Deployment

### Backend
```bash
cd backend
pip install -r requirements.txt

# For production, use a production ASGI server
uvicorn main:app --host 0.0.0.0 --port 8000
```

### Frontend
```bash
cd frontend
npm run build

# Deploy the dist/ directory to your hosting service
# (Vercel, Netlify, AWS S3, etc.)
```

## ğŸ’¡ Performance Notes

### Apple Silicon (M1/M2/M3/M4)
- whisper.cpp automatically uses Metal for GPU acceleration
- Transcription is significantly faster than real-time
- No additional configuration needed

### Intel Macs
- CPU-based processing
- Still fast for the base model
- Consider using smaller audio files for best performance

## ğŸ”— Links

- **Original Design**: [Figma](https://www.figma.com/design/oHlArZbdYorZZ6YhZPB9Tu/B2B-AI-Talent-Analysis-App)
- **whisper.cpp**: [GitHub](https://github.com/ggerganov/whisper.cpp)
- **FastAPI**: [Documentation](https://fastapi.tiangolo.com/)
- **React**: [Documentation](https://react.dev/)

## ğŸ“„ License

MIT License - See individual component licenses for details.

---

**Built with â¤ï¸ for intelligent talent analysis**
